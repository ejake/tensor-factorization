{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Introduction to Theano</h1>\n",
    "\n",
    "<h2 align=\"center\">Jorge A. Vanegas</h2>\n",
    "\n",
    "<div align=\"center\"><img src=\"images/mindlab-logo-simple.png\" style=\"width: 160px; display: inline; padding:25px;\"> <img src=\"images/unal-logo.png\" style=\"width: 150px; display: inline; padding: 0 0 20px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "* What‚Äôs Theano?\n",
    "* Using Theano\n",
    "* Basic Usage\n",
    "* ** Advanced Usage ** \n",
    "* ** Case study 1: Logistic Regression ** \n",
    "* ** Case study 2: Multi-layer Perceptron ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using the CPU vs GPU\n",
    "Theano can transparently compile onto different hardware. What device it uses by default depends on your **.theanorc** file and any environment variables defined, as described in detail here: http://deeplearning.net/software/theano/library/config.html \n",
    "\n",
    "For convenience, Theano provides the floatX configuration variable which designates what float accuracy to use. For example, you can run a Python script with certain environment variables set to use the CPU:\n",
    "\n",
    "\n",
    "    THEANO_FLAGS=device=cpu,floatX=float64 python your_script.py\n",
    "\n",
    "or GPU:\n",
    "\n",
    "    THEANO_FLAGS=device=gpu,floatX=float32 python your_script.py\n",
    "    \n",
    "**.theanorc**:\n",
    "\n",
    "    [global]\n",
    "    floatX = float32\n",
    "    device = gpu0\n",
    "    mode=FAST_RUN\n",
    "    exception_verbosity=high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can get the values being used to configure Theano like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "print(theano.config.device)\n",
    "print(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can also get/set them at runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "old_floatX = theano.config.floatX\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Be careful that you're actually using floatX!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# For example, the following will cause var to be a float64 regardless of floatX due to numpy defaults:\n",
    "var = theano.shared(np.array([1.3, 2.4]))\n",
    "print(var.type()) #!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# So, whenever you use a numpy array, make sure to set its dtype to theano.config.floatX\n",
    "var = theano.shared(np.array([1.3, 2.4], dtype=theano.config.floatX))\n",
    "print(var.type())\n",
    "# Revert to old value\n",
    "theano.config.floatX = old_floatX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Testing Theano with GPU\n",
    "\n",
    "    check_theano.py:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in xrange(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "device=cpu\n",
    "<pre><code>\n",
    "$ THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python check_theano.py      \n",
    "[Elemwise{exp,no_inplace}(<TensorType(float32, vector)>)]                                                              \n",
    "Looping 1000 times took 2.204147 seconds                                                                                \n",
    "Result is [ 1.23178029  1.61879337  1.52278066 ...,  2.20771813  2.29967761                                           \n",
    " 1.62323284]                                                                                                            \n",
    "Used the cpu\n",
    "</code></pre>\n",
    "\n",
    "device=gpu\n",
    "<pre><code>\n",
    "$ THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python check_theano.py      \n",
    "Using gpu device 0: Graphics Device (CNMeM is disabled)                                                               [GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
    "Looping 1000 times took 0.311079 seconds                                                                               \n",
    "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761                                           \n",
    "  1.62323296]                                                                                                         \n",
    "Used the gpu\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case study 1: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table style=\"border:none;\">\n",
    "<tr style=\"border:none;\">\n",
    "<td style=\"border:none;\"> \n",
    "    \n",
    "<ul style=\"width: 400px;\">\n",
    "<li>Binary classification</li>\n",
    "<br>\n",
    "<li>Discriminative function</li>\n",
    "<br>\n",
    "$$ ùëù(ùë¶ = 1|ùë•) =\\frac{1}{1+exp(‚àíùë§‚àôùë•‚àíùëè)}$$\n",
    "<br>\n",
    "<li>Objective function</li>\n",
    "<br>\n",
    "Cross-entropy\n",
    "<br>\n",
    "$$ ùêΩ = ‚àíùë¶‚àôlog(ùëù) ‚àí (1 ‚àí ùë¶)‚àôlog(1 ‚àí ùëù) $$\n",
    "<br>\n",
    "</ul>\n",
    "\n",
    "</td>\n",
    "<td style=\"border:none; width: 250px;\">\n",
    "    \n",
    "<img src=\"images/classification-problem.png\" style=\"width: 150px;\"> \n",
    "<img src=\"images/sigmoid.png\" style=\"width: 150px;\"> \n",
    "<img src=\"images/sigmoid-function.png\" style=\"width: 150px;\">\n",
    "\n",
    "</td> \n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Case study 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from collections import OrderedDict \n",
    "\n",
    "rng = numpy.random\n",
    "\n",
    "N = 400 # number of samples\n",
    "feats = 784 # dimensionality of features\n",
    "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n",
    "training_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# declare Theano symbolic variables\n",
    "x = T.matrix('x')\n",
    "y = T.vector('y')\n",
    "w = theano.shared(rng.randn(784), name='w')\n",
    "b = theano.shared(0., name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print \"Initial model:\"\n",
    "print w.get_value(), b.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Construct Theano expression graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ ùëù(ùë¶ = 1|ùë•) =\\frac{1}{1+exp(‚àíùë§‚àôùë•‚àíùëè)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b)) # probability that target = 1\n",
    "prediction = p_1 > 0.5 # the prediction threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ cost = avg(J(p_1)) + \\lambda‚àô\\left \\| W \\right \\|_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xent = -y*T.log(p_1) - (1 - y)*T.log(1 - p_1) # cross-entropy loss function\n",
    "cost = xent.mean() + 0.01 * (w**2).sum() # the cost to minimize\n",
    "\n",
    "gw, gb = T.grad(cost, [w, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Gradient descent:  $ \\theta \\leftarrow \\theta - \\gamma \\cdot \\frac{\\partial }{\\partial \\theta}L $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "train = theano.function(\n",
    "    inputs = [x, y],\n",
    "    outputs = [prediction, xent, cost],\n",
    "    updates = \n",
    "        OrderedDict([(w, w - 0.1*gw), \n",
    "                     (b, b - 0.1*gb)]),\n",
    "    allow_input_downcast=True)\n",
    "predict = theano.function(\n",
    "    inputs = [x], \n",
    "    outputs = prediction,\n",
    "    allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "predictions = []\n",
    "errors = []\n",
    "costs = []\n",
    "fmeasures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "for i in range(training_steps):\n",
    "    pred, err, cost = train(D[0], D[1])\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    errors.append(err)\n",
    "    costs.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# show errors\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline\n",
    "\n",
    "iterations = range(training_steps)\n",
    "\n",
    "for i in iterations:\n",
    "    fmeasures.append(f1_score(D[1], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(iterations, costs, 'b')\n",
    "plt.title('Learning process')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(iterations, fmeasures, 'b')\n",
    "plt.title('Predictions')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"F-measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# print \"Final model:\"\n",
    "# print w.get_value(), b.get_value()\n",
    "# print \"target values for D: \", D[1]\n",
    "# print \"predictions on D: \", predict(D[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case study 2: Multi-Layer Perceptron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table style=\"border:none;\">\n",
    "<tr style=\"border:none;\">\n",
    "<td style=\"border:none;\"> \n",
    "    \n",
    "<ul style=\"width: 450px;\">\n",
    "<li>Hidden layer(s)</li>\n",
    "<br>\n",
    "<li>Discriminative function</li>\n",
    "<br>\n",
    "$$ ùëù(ùë¶ = 1|ùë•) = f(w_2‚àô(g(w_1‚àôx + b_1) + b_2))$$\n",
    "<br>\n",
    "$f$ and $g$ can be $sigmoid/tanh$ functions\n",
    "<br>\n",
    "<br>\n",
    "<li>Objective function</li>\n",
    "<br>\n",
    "Cross-entropy\n",
    "<br>\n",
    "$$ ùêΩ = ‚àíùë¶‚àôlog(ùëù) ‚àí (1 ‚àí ùë¶)‚àôlog(1 ‚àí ùëù) $$\n",
    "<br>\n",
    "</ul>\n",
    "\n",
    "</td>\n",
    "<td style=\"border:none; width: 250px;\">\n",
    "    \n",
    "<img src=\"images/multilayer.png\" style=\"width: 200px;\"> \n",
    "<img src=\"images/sigmoid-function.png\" style=\"width: 200px;\">\n",
    "\n",
    "</td> \n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Case study 2: Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "rng = numpy.random\n",
    "\n",
    "N = 400 # number of samples\n",
    "feats = 784 # dimensionality of features\n",
    "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n",
    "training_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# declare Theano symbolic variables\n",
    "x = T.matrix('x')\n",
    "y = T.vector('y')\n",
    "w_1 = theano.shared(rng.randn(784,300), name='w1')\n",
    "b_1 = theano.shared(numpy.zeros((300,)), name='b1')\n",
    "w_2 = theano.shared(rng.randn(300), name='w2')\n",
    "b_2 = theano.shared(0., name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# print \"Initial model:\"\n",
    "# print w_1.get_value(), b_1.get_value()\n",
    "# print w_2.get_value(), b_2.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Construct Theano expression graph\n",
    "p_1 = T.nnet.sigmoid(-T.dot(T.nnet.sigmoid(-T.dot(x, w_1) - b_1), w_2) - b_2)\n",
    "# probability that target = 1\n",
    "prediction = p_1 > 0.5 # the prediction threshold\n",
    "xent = -y*T.log(p_1) - (1 - y)*T.log(1 - p_1) # cross-entropy loss func\n",
    "cost = xent.mean() + 0.01 * (w**2).sum() # the cost to minimize\n",
    "gw_1, gb_1, gw_2, gb_2 = T.grad(cost, [w_1, b_1, w_2, b_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "train = theano.function(\n",
    "    inputs = [x, y],\n",
    "    outputs = [prediction, xent, cost],\n",
    "    updates = \n",
    "        OrderedDict([(w_1, w_1 - 0.1*gw_1), \n",
    "                     (b_1, b_1 - 0.1*gb_1),\n",
    "                     (w_2, w_2 - 0.1*gw_2),\n",
    "                     (b_2, b_2 - 0.1*gb_2)\n",
    "                    ]),\n",
    "    allow_input_downcast=True)\n",
    "predict = theano.function(\n",
    "    inputs = [x], \n",
    "    outputs = prediction, \n",
    "    allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "predictions = []\n",
    "errors = []\n",
    "costs = []\n",
    "fmeasures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "for i in range(training_steps):\n",
    "    pred, err, cost = train(D[0], D[1])\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    errors.append(err)\n",
    "    costs.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# show errors\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline\n",
    "\n",
    "iterations = range(training_steps)\n",
    "\n",
    "for i in iterations:\n",
    "    fmeasures.append(f1_score(D[1], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(iterations, costs, 'b')\n",
    "plt.title('Learning process')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(iterations, fmeasures, 'b')\n",
    "plt.title('Predictions')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"F-measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# print \"Final model:\"\n",
    "# print w_1.get_value(), b_1.get_value()\n",
    "# print w_2.get_value(), b_2.get_value()\n",
    "# print \"target values for D: \", D[1]\n",
    "# print \"predictions on D: \", predict(D[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
