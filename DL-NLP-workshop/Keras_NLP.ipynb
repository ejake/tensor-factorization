{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras and Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sebastian Sierra - DL-NLP workshop\n",
    "<img src=\"http://m.memegen.com/4j0k0i.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "* What is Keras?\n",
    "  * Installing Keras\n",
    "* Models in Keras: Sequential vs Graph\n",
    "* Recurrent layers in keras.\n",
    "  * LSTM and bidirectional LSTM\n",
    "  * GRU\n",
    "* Creating new layers in Keras\n",
    "* Ex: Using Keras and gensim to solve semantic similarity task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Keras?\n",
    "\n",
    "It's a Deep Learning library for Theano and TensorFlow. Keras is also built upon four guiding principles:\n",
    "* Modularity.\n",
    "  *  Neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules.\n",
    "* Minimalism.\n",
    "* Easy extensibility.\n",
    "* Work with Python.\n",
    "\n",
    "Keras is suited for easy and fast prototyping. It also supports **convolutional neural networks** and **recurrent neural networks** and easy combination between both. Besides it enables multi-input and multi-output training. Keras runs on GPU or CPU.\n",
    "\n",
    "**Further documentation** can be found on [Keras Docs](http://keras.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras requirements are:\n",
    "* numpy, scipy\n",
    "* pyyaml\n",
    "* HDF5 and h5py\n",
    "* In case of using CNNs: cuDNN\n",
    "\n",
    "In this case we are going to work with **Theano** as backend, so the latest version of **Theano** should be used\n",
    "```bash\n",
    "sudo pip install git+git://github.com/Theano/Theano.git\n",
    "```\n",
    "Finally pip install the latest version of keras\n",
    "```bash\n",
    "sudo pip install keras\n",
    "```\n",
    "Then we check if we have the latest version(>0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.get_distribution(\"keras\").version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models in Keras: Sequential vs Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are the main structure in Keras. There are two kinds of models: Sequential model and Graph model. Sequential is a sequence of layers, organized in the exact order they where added. Graph models are determined by the connections nodes and the connections between their nodes.\n",
    "\n",
    "Sequential models can be easily created:\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "```\n",
    "Then we can add each layer, in this short example we are creating a network with a Embedding layer as input layer, then we add a LSTM, a Dropout layer, a Dense layer that is a standard fully connected layer and finally an Activation layer using a sigmoid function.\n",
    "```python\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model.add(Embedding(input_dim, output_dim, input_length=maxlen))\n",
    "model.add(LSTM(output_dim))\n",
    "model.add(Dropout(prob))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "```\n",
    "\n",
    "One example of Keras' easy extensibility is that we can define functions :\n",
    "```python\n",
    "def tanh(x):\n",
    "    return theano.tensor.tanh(x)\n",
    "\n",
    "model.add(Dense(64, activation=tanh))\n",
    "model.add(Activation(tanh))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other side we have Graph models, that can be created so:\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "model = Graph()\n",
    "```\n",
    "In this case we are defining a bidirectional LSTM for a classification problem. Note that in this case we have to define first the input. *maxlen* stands for the input size that our network will have. The details of the construction of a bidirectional LSTM will be further discussed. At the end of the specification of the network we can see that it is really similar to the specification of the previous network.\n",
    "```python\n",
    "model.add_input(name='input', input_shape=(maxlen,), dtype=int)\n",
    "model.add_node(Embedding(input_dim, output_dim, input_length=maxlen),\n",
    "               name='embedding', input='input')\n",
    "model.add_node(LSTM(output_dim), name='forward', input='embedding')\n",
    "model.add_node(LSTM(output_dim, go_backwards=True), name='backward', input='embedding')\n",
    "model.add_node(Dropout(prob), name='dropout', inputs=['forward', 'backward'])\n",
    "model.add_node(Dense(1, activation='sigmoid'), name='sigmoid', input='dropout')\n",
    "model.add_output(name='output', input='sigmoid')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layers in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Layers are implemented in Keras. It supports LSTM, GRU and SimpleRNN recurrent layers. Each of one can be called easiy using this:\n",
    "```python\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "```\n",
    "Its input is a 3D tensor with shape **(nb_samples, timesteps, input_dim)**. The output will be 3D tensor with shape  **(nb_samples, timesteps, output_dim)**.\n",
    "\n",
    "Keras by default resets the memory of the recurrent network. In some cases we would like to enable statefulness, so the input of the following iteration is fed with the previous state of the network. This can be done specifying `stateful=True` in the layer constructor.\n",
    "\n",
    "We are going to see how a RNN can be used in text classification task and compare the performance of three basic structures: LSTM, GRU and Bidirectional LSTM. Although we have to set our data ready to use in Keras. Keras has a module with some standard datasets, in our case we will work with the sentiment analysis task of the IMDB reviews dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB sentiment analysis task.\n",
    "Sentiment Analysis is a widely known text classification task. In 2011 was released a dataset composed of 25,000 reviews of movies for training and 25,000 reviews for testing [More info](http://ai.stanford.edu/~amaas/data/sentiment/). As its authors claim, the reviews are highly polar. The labels used for this dataset were 0(Negative review) and 1(Positive review). A negative review has a score <= 4 out of 10, and a positive review has a score >= 7 out of 10. Besides, the training and testing sets contain a disjoint set of movies. We will try to predict if a review contains a positive review or a negative one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Graphics Device (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import accuracy\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.datasets import imdb\n",
    "from six.moves import cPickle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from utils.helper_keras import sentence_to_wordlist, review_to_words, load_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define the number of top most frequent words to consider of our Embedding layer, this number will be *max_features*, then we define the maximum length of the input sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we easily load the IMDB data, defining the percentage for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.pkl\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno socket error] [Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a8cf83e22e53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train sequences'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test sequences'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/keras/datasets/imdb.pyc\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(path, nb_words, skip_top, maxlen, test_split, seed, start_char, oov_char, index_from)\u001b[0m\n\u001b[0;32m     11\u001b[0m               start_char=1, oov_char=2, index_from=3):\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://s3.amazonaws.com/text-datasets/imdb.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/keras/datasets/data_utils.pyc\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar)\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mParanoidURLopener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mprogbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self, url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mopen_https\u001b[1;34m(self, url, data)\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrealhost\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Host'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealhost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddheaders\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m             \u001b[0merrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetreply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmessage_body\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0mmessage_body\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[1;31m#message_body was not a string (i.e. it is a file) and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[1;34m\"Connect to a host on a given (SSL) port.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m             \u001b[0mHTTPConnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m         self.sock = self._create_connection((self.host,self.port),\n\u001b[1;32m--> 832\u001b[1;33m                                            self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"getaddrinfo returns an empty list\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno socket error] [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7b759312cb13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a30b471a01c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However this data is not that interpretable. We are going to upload manually the dataset to see how keras is loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acl_path = \"/data1/aclImdb/\"\n",
    "processed_path = \"/data1/IMDB/\"\n",
    "train = pd.read_csv(processed_path+\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv(processed_path+\"labeledTestSet.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"8196_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I dont know why people think this is such a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"7166_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This movie could have been very good, but com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"10633_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I watched this video at a friend's house. I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"319_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"A friend of mine bought this film for £1, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"8713_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;br /&gt;&lt;br /&gt;This movie is full of references....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"2486_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"What happens when an army of wetbacks, towelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"6811_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Although I generally do not like remakes beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"11744_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"7369_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I had a feeling that after \\\"Submerged\\\", thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"12081_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"note to George Litman, and others: the Myster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"3561_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Stephen King adaptation (scripted by King him...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"4489_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"`The Matrix' was an exciting summer blockbust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"3951_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Ulli Lommel's 1980 film 'The Boogey Man' is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"3304_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"This movie is one among the very few Indian m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"9352_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Most people, especially young people, may not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"3374_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"Soylent Green\\\" is one of the best and most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"10782_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Michael Stearns plays Mike, a sexually frustr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"5414_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"This happy-go-luck 1939 military swashbuckler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"10492_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I would love to have that two hours of my lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"3350_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The script for this movie was probably found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"6581_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Looking for Quo Vadis at my local video store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"2203_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Note to all mad scientists everywhere: if you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"689_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"What the ........... is this ? This must, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"9152_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Intrigued by the synopsis (every gay video th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"6077_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Would anyone really watch this RUBBISH if it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>\"9389_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Red Rock West (1993)&lt;br /&gt;&lt;br /&gt;Nicolas Cage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>\"9251_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"what can i say?, ms Erika Eleniak is my favor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>\"1422_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"The spoiler warning is for those people who w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>\"7415_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"What do you call a horror story without horro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>\"7492_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Though not a horror film in the traditional s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>\"7689_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"This was what black society was like before t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>\"12370_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"They probably should have called this movie T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>\"5625_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Attractive Marjorie(Farrah Fawcett)lives in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>\"9397_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Vaguely reminiscent of great 1940's westerns,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>\"5992_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I admit I had no idea what to expect before v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>\"2488_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"To me, the final scene, in which Harris respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>\"9627_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"This is by far the funniest short made by the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>\"3822_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"To be a Buster Keaton fan is to have your hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>\"5983_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I was one of those \\\"few Americans\\\" that gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>\"8021_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Visually disjointed and full of itself, the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>\"3471_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"this movie had more holes than a piece of swi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>\"6034_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Last November, I had a chance to see this fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>\"1988_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"First off, I'd like to make a correction on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>\"7623_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"While originally reluctant to jump on the ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>\"5974_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I heard about this movie when watching VH1's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>\"2034_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I've never been huge on IMAX films. They're c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>\"9416_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Steve McQueen has certainly a lot of loyal fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>\"10994_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Sometimes you wonder how some people get fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>\"10957_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I am a student of film, and have been for sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>\"2372_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Unimaginably stupid, redundant and humiliatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"3453_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It seems like more consideration has gone int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"5064_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I don't believe they made this film. Complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"10905_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"10194_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"8478_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "0       \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1       \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2       \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3       \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4       \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
       "5       \"8196_8\"          1  \"I dont know why people think this is such a b...\n",
       "6       \"7166_2\"          0  \"This movie could have been very good, but com...\n",
       "7      \"10633_1\"          0  \"I watched this video at a friend's house. I'm...\n",
       "8        \"319_1\"          0  \"A friend of mine bought this film for £1, and...\n",
       "9      \"8713_10\"          1  \"<br /><br />This movie is full of references....\n",
       "10      \"2486_3\"          0  \"What happens when an army of wetbacks, towelh...\n",
       "11     \"6811_10\"          1  \"Although I generally do not like remakes beli...\n",
       "12     \"11744_9\"          1  \"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...\n",
       "13      \"7369_1\"          0  \"I had a feeling that after \\\"Submerged\\\", thi...\n",
       "14     \"12081_1\"          0  \"note to George Litman, and others: the Myster...\n",
       "15      \"3561_4\"          0  \"Stephen King adaptation (scripted by King him...\n",
       "16      \"4489_1\"          0  \"`The Matrix' was an exciting summer blockbust...\n",
       "17      \"3951_2\"          0  \"Ulli Lommel's 1980 film 'The Boogey Man' is n...\n",
       "18     \"3304_10\"          1  \"This movie is one among the very few Indian m...\n",
       "19     \"9352_10\"          1  \"Most people, especially young people, may not...\n",
       "20      \"3374_7\"          1  \"\\\"Soylent Green\\\" is one of the best and most...\n",
       "21     \"10782_7\"          1  \"Michael Stearns plays Mike, a sexually frustr...\n",
       "22     \"5414_10\"          1  \"This happy-go-luck 1939 military swashbuckler...\n",
       "23     \"10492_1\"          0  \"I would love to have that two hours of my lif...\n",
       "24      \"3350_3\"          0  \"The script for this movie was probably found ...\n",
       "25      \"6581_7\"          1  \"Looking for Quo Vadis at my local video store...\n",
       "26      \"2203_3\"          0  \"Note to all mad scientists everywhere: if you...\n",
       "27       \"689_1\"          0  \"What the ........... is this ? This must, wit...\n",
       "28      \"9152_1\"          0  \"Intrigued by the synopsis (every gay video th...\n",
       "29      \"6077_1\"          0  \"Would anyone really watch this RUBBISH if it ...\n",
       "...          ...        ...                                                ...\n",
       "24970   \"9389_7\"          1  \"Red Rock West (1993)<br /><br />Nicolas Cage ...\n",
       "24971   \"9251_9\"          1  \"what can i say?, ms Erika Eleniak is my favor...\n",
       "24972  \"1422_10\"          1  \"The spoiler warning is for those people who w...\n",
       "24973   \"7415_2\"          0  \"What do you call a horror story without horro...\n",
       "24974   \"7492_7\"          1  \"Though not a horror film in the traditional s...\n",
       "24975  \"7689_10\"          1  \"This was what black society was like before t...\n",
       "24976  \"12370_4\"          0  \"They probably should have called this movie T...\n",
       "24977   \"5625_8\"          1  \"Attractive Marjorie(Farrah Fawcett)lives in f...\n",
       "24978   \"9397_9\"          1  \"Vaguely reminiscent of great 1940's westerns,...\n",
       "24979   \"5992_7\"          1  \"I admit I had no idea what to expect before v...\n",
       "24980  \"2488_10\"          1  \"To me, the final scene, in which Harris respo...\n",
       "24981  \"9627_10\"          1  \"This is by far the funniest short made by the...\n",
       "24982   \"3822_2\"          0  \"To be a Buster Keaton fan is to have your hea...\n",
       "24983   \"5983_4\"          0  \"I was one of those \\\"few Americans\\\" that gre...\n",
       "24984   \"8021_2\"          0  \"Visually disjointed and full of itself, the d...\n",
       "24985   \"3471_3\"          0  \"this movie had more holes than a piece of swi...\n",
       "24986  \"6034_10\"          1  \"Last November, I had a chance to see this fil...\n",
       "24987   \"1988_9\"          1  \"First off, I'd like to make a correction on a...\n",
       "24988   \"7623_9\"          1  \"While originally reluctant to jump on the ban...\n",
       "24989   \"5974_7\"          1  \"I heard about this movie when watching VH1's ...\n",
       "24990   \"2034_9\"          1  \"I've never been huge on IMAX films. They're c...\n",
       "24991   \"9416_3\"          0  \"Steve McQueen has certainly a lot of loyal fa...\n",
       "24992  \"10994_1\"          0  \"Sometimes you wonder how some people get fund...\n",
       "24993  \"10957_3\"          0  \"I am a student of film, and have been for sev...\n",
       "24994   \"2372_1\"          0  \"Unimaginably stupid, redundant and humiliatin...\n",
       "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
       "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
       "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
       "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
       "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how a review looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\\\"The Classic War of the Worlds\\\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\"critics\\\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\"critics\\\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\"critics\\\" perceive to be its shortcomings.\"\n",
      "Sentiment: 1\n"
     ]
    }
   ],
   "source": [
    "print(train[\"review\"][1])\n",
    "print(\"Sentiment: %d\" % (train[\"sentiment\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"What happens when an army of wetbacks, towelheads, and Godless Eastern European commies gather their forces south of the border? Gary Busey kicks their butts, of course. Another laughable example of Reagan-era cultural fallout, Bulletproof wastes a decent supporting cast headed by L Q Jones and Thalmus Rasulala.\"\n",
      "Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "print(train[\"review\"][10])\n",
    "print(\"Sentiment: %d\" % (train[\"sentiment\"][10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a list of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "clean_train_reviews = [sentence_to_wordlist(review.decode(\"utf8\")) for review in train[\"review\"][:]]\n",
    "corpus_reviews = [sentence_to_wordlist(review.decode(\"utf8\"), tokenized=False) for review in train[\"review\"][:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'the',\n",
       " u'classic',\n",
       " u'war',\n",
       " u'of',\n",
       " u'the',\n",
       " u'worlds',\n",
       " u'by',\n",
       " u'timothy',\n",
       " u'hines',\n",
       " u'is',\n",
       " u'a',\n",
       " u'very',\n",
       " u'entertaining',\n",
       " u'film',\n",
       " u'that',\n",
       " u'obviously',\n",
       " u'goes',\n",
       " u'to',\n",
       " u'great',\n",
       " u'effort',\n",
       " u'and',\n",
       " u'lengths',\n",
       " u'to',\n",
       " u'faithfully',\n",
       " u'recreate',\n",
       " u'h',\n",
       " u'g',\n",
       " u'wells',\n",
       " u'classic',\n",
       " u'book',\n",
       " u'mr',\n",
       " u'hines',\n",
       " u'succeeds',\n",
       " u'in',\n",
       " u'doing',\n",
       " u'so',\n",
       " u'i',\n",
       " u'and',\n",
       " u'those',\n",
       " u'who',\n",
       " u'watched',\n",
       " u'his',\n",
       " u'film',\n",
       " u'with',\n",
       " u'me',\n",
       " u'appreciated',\n",
       " u'the',\n",
       " u'fact',\n",
       " u'that',\n",
       " u'it',\n",
       " u'was',\n",
       " u'not',\n",
       " u'the',\n",
       " u'standard',\n",
       " u'predictable',\n",
       " u'hollywood',\n",
       " u'fare',\n",
       " u'that',\n",
       " u'comes',\n",
       " u'out',\n",
       " u'every',\n",
       " u'year',\n",
       " u'e',\n",
       " u'g',\n",
       " u'the',\n",
       " u'spielberg',\n",
       " u'version',\n",
       " u'with',\n",
       " u'tom',\n",
       " u'cruise',\n",
       " u'that',\n",
       " u'had',\n",
       " u'only',\n",
       " u'the',\n",
       " u'slightest',\n",
       " u'resemblance',\n",
       " u'to',\n",
       " u'the',\n",
       " u'book',\n",
       " u'obviously',\n",
       " u'everyone',\n",
       " u'looks',\n",
       " u'for',\n",
       " u'different',\n",
       " u'things',\n",
       " u'in',\n",
       " u'a',\n",
       " u'movie',\n",
       " u'those',\n",
       " u'who',\n",
       " u'envision',\n",
       " u'themselves',\n",
       " u'as',\n",
       " u'amateur',\n",
       " u'critics',\n",
       " u'look',\n",
       " u'only',\n",
       " u'to',\n",
       " u'criticize',\n",
       " u'everything',\n",
       " u'they',\n",
       " u'can',\n",
       " u'others',\n",
       " u'rate',\n",
       " u'a',\n",
       " u'movie',\n",
       " u'on',\n",
       " u'more',\n",
       " u'important',\n",
       " u'bases',\n",
       " u'like',\n",
       " u'being',\n",
       " u'entertained',\n",
       " u'which',\n",
       " u'is',\n",
       " u'why',\n",
       " u'most',\n",
       " u'people',\n",
       " u'never',\n",
       " u'agree',\n",
       " u'with',\n",
       " u'the',\n",
       " u'critics',\n",
       " u'we',\n",
       " u'enjoyed',\n",
       " u'the',\n",
       " u'effort',\n",
       " u'mr',\n",
       " u'hines',\n",
       " u'put',\n",
       " u'into',\n",
       " u'being',\n",
       " u'faithful',\n",
       " u'to',\n",
       " u'h',\n",
       " u'g',\n",
       " u'wells',\n",
       " u'classic',\n",
       " u'novel',\n",
       " u'and',\n",
       " u'we',\n",
       " u'found',\n",
       " u'it',\n",
       " u'to',\n",
       " u'be',\n",
       " u'very',\n",
       " u'entertaining',\n",
       " u'this',\n",
       " u'made',\n",
       " u'it',\n",
       " u'easy',\n",
       " u'to',\n",
       " u'overlook',\n",
       " u'what',\n",
       " u'the',\n",
       " u'critics',\n",
       " u'perceive',\n",
       " u'to',\n",
       " u'be',\n",
       " u'its',\n",
       " u'shortcomings']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we calculate the frequency distribution of the terms in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_reviews=' '.join(corpus_reviews)\n",
    "tokens = nltk.word_tokenize(whole_reviews)\n",
    "fdist=FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/__main__.py:2: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  from IPython.kernel.zmq import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23922</th>\n",
       "      <td>the</td>\n",
       "      <td>336645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34151</th>\n",
       "      <td>and</td>\n",
       "      <td>164103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62815</th>\n",
       "      <td>a</td>\n",
       "      <td>163132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34662</th>\n",
       "      <td>of</td>\n",
       "      <td>145853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39414</th>\n",
       "      <td>to</td>\n",
       "      <td>135698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28602</th>\n",
       "      <td>is</td>\n",
       "      <td>107315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23249</th>\n",
       "      <td>it</td>\n",
       "      <td>96444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62246</th>\n",
       "      <td>in</td>\n",
       "      <td>93958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27488</th>\n",
       "      <td>i</td>\n",
       "      <td>87641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59360</th>\n",
       "      <td>this</td>\n",
       "      <td>75966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61895</th>\n",
       "      <td>that</td>\n",
       "      <td>73275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>s</td>\n",
       "      <td>66080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42747</th>\n",
       "      <td>was</td>\n",
       "      <td>48194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20673</th>\n",
       "      <td>as</td>\n",
       "      <td>46934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19379</th>\n",
       "      <td>for</td>\n",
       "      <td>44333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>with</td>\n",
       "      <td>44120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58656</th>\n",
       "      <td>movie</td>\n",
       "      <td>44030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32370</th>\n",
       "      <td>but</td>\n",
       "      <td>42613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48582</th>\n",
       "      <td>film</td>\n",
       "      <td>40146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43840</th>\n",
       "      <td>t</td>\n",
       "      <td>34402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Term  Frequency\n",
       "23922    the     336645\n",
       "34151    and     164103\n",
       "62815      a     163132\n",
       "34662     of     145853\n",
       "39414     to     135698\n",
       "28602     is     107315\n",
       "23249     it      96444\n",
       "62246     in      93958\n",
       "27488      i      87641\n",
       "59360   this      75966\n",
       "61895   that      73275\n",
       "1856       s      66080\n",
       "42747    was      48194\n",
       "20673     as      46934\n",
       "19379    for      44333\n",
       "2212    with      44120\n",
       "58656  movie      44030\n",
       "32370    but      42613\n",
       "48582   film      40146\n",
       "43840      t      34402"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df = pd.DataFrame(fdist.items(), columns=['Term', 'Frequency'])\n",
    "ordered_freqdf = freq_df.sort([\"Frequency\"], ascending=[False])\n",
    "ordered_freqdf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexed_dict = {key: value for (key, value) in zip(ordered_freqdf[\"Term\"][:], range(len(ordered_freqdf[\"Term\"][:])))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "i = 1\n",
    "for review in clean_train_reviews:\n",
    "    tmp = []\n",
    "    for x in review:\n",
    "        if indexed_dict.has_key(x):\n",
    "            tmp.append(indexed_dict[x])\n",
    "    X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 347,\n",
       " 318,\n",
       " 3,\n",
       " 0,\n",
       " 3207,\n",
       " 32,\n",
       " 3711,\n",
       " 7292,\n",
       " 5,\n",
       " 2,\n",
       " 53,\n",
       " 439,\n",
       " 18,\n",
       " 10,\n",
       " 528,\n",
       " 264,\n",
       " 4,\n",
       " 83,\n",
       " 764,\n",
       " 1,\n",
       " 11377,\n",
       " 4,\n",
       " 12392,\n",
       " 9080,\n",
       " 1790,\n",
       " 1175,\n",
       " 3661,\n",
       " 347,\n",
       " 265,\n",
       " 435,\n",
       " 7292,\n",
       " 2852,\n",
       " 7,\n",
       " 392,\n",
       " 35,\n",
       " 8,\n",
       " 1,\n",
       " 145,\n",
       " 34,\n",
       " 291,\n",
       " 25,\n",
       " 18,\n",
       " 15,\n",
       " 68,\n",
       " 2492,\n",
       " 0,\n",
       " 188,\n",
       " 10,\n",
       " 6,\n",
       " 12,\n",
       " 22,\n",
       " 0,\n",
       " 1247,\n",
       " 709,\n",
       " 332,\n",
       " 2362,\n",
       " 10,\n",
       " 260,\n",
       " 43,\n",
       " 173,\n",
       " 272,\n",
       " 756,\n",
       " 1175,\n",
       " 0,\n",
       " 3031,\n",
       " 308,\n",
       " 15,\n",
       " 774,\n",
       " 3476,\n",
       " 10,\n",
       " 66,\n",
       " 62,\n",
       " 0,\n",
       " 3627,\n",
       " 4017,\n",
       " 4,\n",
       " 0,\n",
       " 265,\n",
       " 528,\n",
       " 293,\n",
       " 266,\n",
       " 14,\n",
       " 269,\n",
       " 181,\n",
       " 7,\n",
       " 2,\n",
       " 16,\n",
       " 145,\n",
       " 34,\n",
       " 20053,\n",
       " 523,\n",
       " 13,\n",
       " 2316,\n",
       " 1386,\n",
       " 165,\n",
       " 62,\n",
       " 4,\n",
       " 7059,\n",
       " 282,\n",
       " 31,\n",
       " 47,\n",
       " 399,\n",
       " 944,\n",
       " 2,\n",
       " 16,\n",
       " 21,\n",
       " 50,\n",
       " 657,\n",
       " 11228,\n",
       " 37,\n",
       " 109,\n",
       " 2146,\n",
       " 60,\n",
       " 5,\n",
       " 133,\n",
       " 88,\n",
       " 76,\n",
       " 112,\n",
       " 1014,\n",
       " 15,\n",
       " 0,\n",
       " 1386,\n",
       " 67,\n",
       " 498,\n",
       " 0,\n",
       " 764,\n",
       " 435,\n",
       " 7292,\n",
       " 270,\n",
       " 81,\n",
       " 109,\n",
       " 2707,\n",
       " 4,\n",
       " 1790,\n",
       " 1175,\n",
       " 3661,\n",
       " 347,\n",
       " 636,\n",
       " 1,\n",
       " 67,\n",
       " 252,\n",
       " 6,\n",
       " 4,\n",
       " 27,\n",
       " 53,\n",
       " 439,\n",
       " 9,\n",
       " 89,\n",
       " 6,\n",
       " 753,\n",
       " 4,\n",
       " 4781,\n",
       " 46,\n",
       " 0,\n",
       " 1386,\n",
       " 9246,\n",
       " 4,\n",
       " 27,\n",
       " 90,\n",
       " 5665]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can get again *X_train*, *y_train* and *X_test*, *y_test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_imdb(X, train[\"sentiment\"].tolist(), nb_words=max_features, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the sequences will be padded(where the length is less than 100):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (20000, 100)\n",
      "X_test shape: (5000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build the model as we have previously done.  \n",
    "## LSTM\n",
    "<img src=\"https://github.com/Element-Research/rnn/blob/master/doc/image/LSTM.png?raw=true\" style=\"width: 50%; height: 50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With compile function we can set the objective function, the optimizer and the class evaluation mode. The following objectives are available:\n",
    "* mean_squared_error / mse\n",
    "* root_mean_squared_error / rmse\n",
    "* mean_absolute_error / mae\n",
    "* mean_absolute_percentage_error / mape\n",
    "* mean_squared_logarithmic_error / msle\n",
    "* squared_hinge\n",
    "* hinge\n",
    "* binary_crossentropy: logloss.\n",
    "* categorical_crossentropy: multiclass logloss\n",
    "\n",
    "On the side of the optimizers, Keras provide us these:\n",
    "* SGD\n",
    "* RMSprop\n",
    "* Adagrad\n",
    "* Adadelta\n",
    "* Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can use *fit* function(In a sci-kit learn fashion) to train the model. *evaluate* will show the performance of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 108s - loss: 0.4412 - acc: 0.7972   \n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 160s - loss: 0.2596 - acc: 0.9008   \n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 214s - loss: 0.1516 - acc: 0.9449   \n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 215s - loss: 0.0905 - acc: 0.9714   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa60a756050>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=4, show_accuracy=True)\n",
    "#score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, show_accuracy=True)\n",
    "#print('Test score:', score)\n",
    "#print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily use a GRU instead of a LSTM. Most of the code will be similar to the previous one.\n",
    "## GRU\n",
    "<img src=\"https://camo.githubusercontent.com/3ea758e7796a3e21d6b002f7aa588361d7e0bb7b/687474703a2f2f64336b62707a626d63796e6e6d782e636c6f756466726f6e742e6e65742f77702d636f6e74656e742f75706c6f6164732f323031352f31302f53637265656e2d53686f742d323031352d31302d32332d61742d31302e33362e35312d414d2e706e67\" style=\"width: 75%; height: 75%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-2bb3aeab2014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, class_mode)\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[0mpredict_ins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_with_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         self.function = theano.function(inputs, outputs, updates=updates,\n\u001b[1;32m--> 362\u001b[1;33m                                         allow_input_downcast=True, **kwargs)\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    315\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    524\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1776\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m             defaults)\n\u001b[0m\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[1;32m-> 1642\u001b[1;33m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0m\u001b[0;32m   1643\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m    688\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[0;32m    689\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m                              storage_map=storage_map)[:3]\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36mmake_all\u001b[1;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                                  \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                                  no_recycling))\n\u001b[0m\u001b[0;32m   1038\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lazy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m                     \u001b[1;31m# We don't want all ops maker to think about lazy Ops.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    866\u001b[0m                                \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m                                \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m                                on_unused_input='ignore')\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;31m# Analyse the compile inner function to determine which inputs and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    315\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    524\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1776\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m             defaults)\n\u001b[0m\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[1;32m-> 1642\u001b[1;33m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0m\u001b[0;32m   1643\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m    688\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[0;32m    689\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m                              storage_map=storage_map)[:3]\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36mmake_all\u001b[1;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                                  \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                                  no_recycling))\n\u001b[0m\u001b[0;32m   1038\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lazy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m                     \u001b[1;31m# We don't want all ops maker to think about lazy Ops.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    285\u001b[0m                                     enable_cuda=False)\n\u001b[0;32m    286\u001b[0m         return super(GpuOp, self).make_thunk(node, storage_map,\n\u001b[1;32m--> 287\u001b[1;33m                                              compute_map, no_recycling)\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m theano.compile.debugmode.default_make_thunk.append(\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[1;32m--> 932\u001b[1;33m                                          no_recycling)\n\u001b[0m\u001b[0;32m    933\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Falling back on perform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[1;32m--> 850\u001b[1;33m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[0;32m    851\u001b[0m         \u001b[0mfill_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1205\u001b[0m         cthunk, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[0;32m   1206\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m             keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36m__compile__\u001b[1;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                                     \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m                                     \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m                                     keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1153\u001b[0m         return (thunk,\n\u001b[0;32m   1154\u001b[0m                 [link.Container(input, storage) for input, storage in\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mcthunk_factory\u001b[1;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[1;32m-> 1602\u001b[1;33m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m         \u001b[0mvars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/cmodule.pyc\u001b[0m in \u001b[0;36mmodule_from_key\u001b[1;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[1;34m(self, location)\u001b[0m\n\u001b[0;32m   1511\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1512\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1513\u001b[1;33m                 preargs=preargs)\n\u001b[0m\u001b[0;32m   1514\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1515\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/sandbox/cuda/nvcc_compiler.pyc\u001b[0m in \u001b[0;36mcompile_str\u001b[1;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, rpaths, py_module, hide_symbols)\u001b[0m\n\u001b[0;32m    343\u001b[0m             p = subprocess.Popen(\n\u001b[0;32m    344\u001b[0m                     cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mnvcc_stdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnvcc_stderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36mcommunicate\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_communicate\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_has_poll\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m                 \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communicate_with_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communicate_with_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_communicate_with_poll\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1461\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mfd2file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1462\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1463\u001b[1;33m                     \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1464\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")\n",
    "\n",
    "print(\"----------------------\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=4, validation_data=(X_test, y_test), show_accuracy=True)\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, show_accuracy=True)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following case we will use a little more complicated structure. A bidirectional LSTM, it will be built using a Graph model. The main key is to declare two LSTM, one of them have to be enabled to go backward. Unfortunately documentation about this functionality is not clear.  \n",
    "<img src=\"http://zhaoshuaijiang.com/paper_image/Bidirectional_RNN.png\" />\n",
    "M. Schuster and K. K. Paliwal. [Bidirectional Recurrent Neural Networks](http://www.di.ufpe.br/~fnj/RNA/bibliografia/BRNN.pdf). IEEE Transactions on Signal\n",
    "Processing, vol. 45, pp. 2673–2681, 1997."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Graph()\n",
    "model.add_input(name='input', input_shape=(maxlen,), dtype=int)\n",
    "model.add_node(Embedding(max_features, 128, input_length=maxlen),\n",
    "               name='embedding', input='input')\n",
    "model.add_node(LSTM(64), name='forward', input='embedding')\n",
    "model.add_node(LSTM(64, go_backwards=True), name='backward', input='embedding')\n",
    "model.add_node(Dropout(0.5), name='dropout', inputs=['forward', 'backward'])\n",
    "model.add_node(Dense(1, activation='sigmoid'), name='sigmoid', input='dropout')\n",
    "model.add_output(name='output', input='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time instead of using *evaluate* function, we will evaluate it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile('adam', {'output': 'binary_crossentropy'})\n",
    "\n",
    "print('--------------------')\n",
    "model.fit({'input': X_train, 'output': y_train}, batch_size=batch_size, nb_epoch=4)\n",
    "acc = accuracy(y_test, np.round(np.array(model.predict({'input': X_test},\n",
    "                                               batch_size=batch_size)['output'])))\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sense of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform prediction using this model. Let's take a negative and a positive example. (From the test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_test_reviews = [sentence_to_wordlist(review.decode(\"utf8\")) for review in test[\"review\"][:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(' '.join(clean_test_reviews[2]))\n",
    "print(\"Sentiment= %d\" % (test[\"sentiment\"][2]))\n",
    "print(' '.join(clean_test_reviews[4]))\n",
    "print(\"Sentiment= %d\" % (test[\"sentiment\"][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add a neutral review to see how it behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_X = []\n",
    "i = 1\n",
    "additional_examples = \"This movie was amazing, though, I did't like when Tyrion dies.\"\n",
    "\n",
    "for review in [clean_test_reviews[2], clean_test_reviews[4], sentence_to_wordlist(additional_examples)]:\n",
    "    tmp = []\n",
    "    for x in review:\n",
    "        if indexed_dict.has_key(x):\n",
    "            tmp.append(indexed_dict[x])\n",
    "    testing_X.append(tmp)\n",
    "(new_X, new_y), _ = load_imdb(testing_X, [1, 0, 1], nb_words=max_features, test_split=0.)\n",
    "new_X = sequence.pad_sequences(new_X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still a problem where you'd want to predict chains larger than 100 tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(new_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict({'input': np.array(new_X)}, batch_size=batch_size)['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras and gensim to solve Semantic Similarity task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex: Now we are going to apply Keras in another NLP task. Semantic Similarity task has become a central problem in NLP. Recently a dataset was introduced for the Semeval, it was named SICK((Sentences Involving Compositional Knowledge). Further info can be found at [SICK dataset](http://clic.cimec.unitn.it/composes/sick.html). The SICK data set consists of about 10,000 English sentence pairs, generated starting from two existing sets: the 8K ImageFlickr data set and the SemEval 2012 STS MSR-Video Description data set. Each sentence pair was annotated for relatedness by means of crowdsourcing techniques. In the final set, gold scores were distributed as follows: the relatednes scoring resulted in 923 pairs within the [1,2) range, 1373 pairs within the [2,3) range, 3872 pairs within the [3,4) range, and 3672 pairs within the [4,5] range. This exercise is part of Skip-thoughts work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we will define the architecture to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy       \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sick_data=\"/home/datasets/datasets1/skip_thoughts_models/skip-thoughts/data/\"\n",
    "model_path = \"/home/datasets/datasets1/word2vec-embeddings/GoogleNews-vectors-negative300.bin.gz\"\n",
    "def prepare_model(ninputs=9600, nclass=5):\n",
    "    \"\"\"\n",
    "    Set up and compile the model architecture (Logistic regression)\n",
    "    \"\"\"\n",
    "    lrmodel = Sequential()\n",
    "    lrmodel.add(Dense(ninputs))\n",
    "    lrmodel.add(Activation('softmax'))\n",
    "    lrmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return lrmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(lrmodel, X, Y, devX, devY, devscores):\n",
    "    \"\"\"\n",
    "    Train model, using pearsonr on dev for early stopping\n",
    "    \"\"\"\n",
    "    done = False\n",
    "    best = -1.0\n",
    "    r = np.arange(1,6)\n",
    "\n",
    "    while not done:\n",
    "        # Every 100 epochs, check Pearson on development set\n",
    "        lrmodel.fit(X, Y, verbose=2, shuffle=False, validation_data=(devX, devY))\n",
    "        yhat = np.dot(lrmodel.predict_proba(devX, verbose=2), r)\n",
    "        score = pearsonr(yhat, devscores)[0]\n",
    "        if score > best:\n",
    "            print(score)\n",
    "            best = score\n",
    "            bestlrmodel = copy.deepcopy(lrmodel)\n",
    "        else:\n",
    "            done = True\n",
    "\n",
    "    yhat = np.dot(bestlrmodel.predict_proba(devX, verbose=2), r)\n",
    "    score = pearsonr(yhat, devscores)[0]\n",
    "    print('Dev Pearson: ' + str(score))\n",
    "    return bestlrmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels, nclass=5):\n",
    "    \"\"\"\n",
    "    Label encoding from Tree LSTM paper (Tai, Socher, Manning)\n",
    "    \"\"\"\n",
    "    Y = np.zeros((len(labels), nclass)).astype('float32')\n",
    "    for j, y in enumerate(labels):\n",
    "        for i in range(nclass):\n",
    "            if i+1 == np.floor(y) + 1:\n",
    "                Y[j,i] = y - np.floor(y)\n",
    "            if i+1 == np.floor(y):\n",
    "                Y[j,i] = np.floor(y) - y + 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(loc=sick_data):                                                                                                      \n",
    "    \"\"\"                                                                                                                            \n",
    "    Load SICK\n",
    "    \"\"\"                                                                                                                            \n",
    "    trainA, trainB, devA, devB, testA, testB = [],[],[],[],[],[]                                                                   \n",
    "    trainS, devS, testS = [],[],[]                                                                                                 \n",
    "                                                                                                                                   \n",
    "    with open(loc + 'SICK_train.txt', 'rb') as f:                                                                                  \n",
    "        for line in f:                                                                                                             \n",
    "            text = line.strip().split('\\t')                                                                                        \n",
    "            trainA.append(text[1])                                                                                                 \n",
    "            trainB.append(text[2])                                                                                                 \n",
    "            trainS.append(text[3])                                                                                                 \n",
    "    with open(loc + 'SICK_trial.txt', 'rb') as f:                                                                                  \n",
    "        for line in f:                                                                                                             \n",
    "            text = line.strip().split('\\t')                                                                                        \n",
    "            devA.append(text[1])                                                                                                   \n",
    "            devB.append(text[2])                                                                                                   \n",
    "            devS.append(text[3])                                                                                                   \n",
    "    with open(loc + 'SICK_test_annotated.txt', 'rb') as f:                                                                         \n",
    "        for line in f:                                                                                                             \n",
    "            text = line.strip().split('\\t')                                                                                        \n",
    "            testA.append(text[1])                                                                                                  \n",
    "            testB.append(text[2])                                                                                                  \n",
    "            testS.append(text[3])                                                                                                  \n",
    "                                                                                                                                   \n",
    "    trainS = [float(s) for s in trainS[1:]]                                                                                        \n",
    "    devS = [float(s) for s in devS[1:]]                                                                                            \n",
    "    testS = [float(s) for s in testS[1:]]                                                                                          \n",
    "                                                                                                                                   \n",
    "    return [trainA[1:], trainB[1:]], [devA[1:], devB[1:]], [testA[1:], testB[1:]], [trainS, devS, testS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_word2vec(model, dataset):\n",
    "    #model = Word2Vec.load_word2vec_format(model_path, binary=True)\n",
    "    #Replace anything but a character for a space, lowercase everything and tokenize\n",
    "    #Pending to add stop words\n",
    "    trainA = [word_tokenize(re.sub(\"[^a-zA-Z]\", \" \", t).lower()) for t in dataset[0][:]]\n",
    "    trainB = [word_tokenize(re.sub(\"[^a-zA-Z]\", \" \", t).lower()) for t in dataset[1][:]]\n",
    "    feat_trainA = [[model[t] for t in sentence if model.vocab.has_key(t) ] for sentence in trainA]\n",
    "    feat_trainB = [[model[t] for t in sentence if model.vocab.has_key(t) ] for sentence in trainB]\n",
    "    return feat_trainA, feat_trainB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, dev, test, scores = load_data()                                                                                         \n",
    "train[0], train[1], scores[0] = shuffle(train[0], train[1], scores[0], random_state=1234)\n",
    "model = Word2Vec.load_word2vec_format(model_path, binary=True)\n",
    "feat_trainA, feat_trainB = encode_word2vec(model, train)\n",
    "feat_devA, feat_devB = encode_word2vec(model, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_featA = np.array([np.sum(sentence, axis=0) for sentence in feat_trainA])\n",
    "agg_featB = np.array([np.sum(sentence, axis=0) for sentence in feat_trainB])\n",
    "agg_devA = np.array([np.sum(sentence, axis=0) for sentence in feat_devA])\n",
    "agg_devB = np.array([np.sum(sentence, axis=0) for sentence in feat_devB])\n",
    "trainF = np.c_[np.abs(agg_featA - agg_featB), agg_featA * agg_featB]\n",
    "devF = np.c_[np.abs(agg_devA - agg_devB), agg_devA * agg_devB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainY = encode_labels(scores[0])\n",
    "devY = encode_labels(scores[1])\n",
    "lrmodel = prepare_model(ninputs=trainF.shape[1])\n",
    "bestlrmodel = train_model(lrmodel, trainF, trainY, devF, devY, scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_testA, feat_testB = encode_word2vec(model, test)\n",
    "agg_testA = np.array([np.sum(sentence, axis=0) for sentence in feat_testA])\n",
    "agg_testB = np.array([np.sum(sentence, axis=0) for sentence in feat_testB])\n",
    "testF = np.c_[np.abs(agg_testA - agg_testB), agg_testA * agg_testB]\n",
    "\n",
    "print 'Evaluating...'\n",
    "r = np.arange(1,6)\n",
    "yhat = np.dot(bestlrmodel.predict_proba(testF, verbose=2), r)\n",
    "pr = pearsonr(yhat, scores[2])[0]\n",
    "sr = spearmanr(yhat, scores[2])[0]\n",
    "se = mse(yhat, scores[2])\n",
    "print 'Test Pearson: ' + str(pr)\n",
    "print 'Test Spearman: ' + str(sr)\n",
    "print 'Test MSE: ' + str(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About us\n",
    "<img src=\"https://sites.google.com/a/unal.edu.co/mindlab/_/rsrc/1353286903227/config/customLogo.gif?revision=10\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
